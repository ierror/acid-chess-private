
##

# 1
0.03697541178691955

# 2
Epoch: [89]  [48/49]  eta: 0:00:02  lr: 0.000007  loss: 0.0679 (0.0700)  loss_classifier: 0.0111 (0.0118)  loss_box_reg: 0.0194 (0.0193)  loss_mask: 0.0347 (0.0358)  loss_objectness:
0.0002 (0.0007)  loss_rpn_box_reg: 0.0024 (0.0024)  time: 2.3986  data: 0.1742  max mem: 11006
Epoch: [89] Total time: 0:01:58 (2.4278 s / it)
model saved for loss_mask=0.035843346610057114

#3
Epoch    19: reducing learning rate of group 0 to 3.7500e-04

# 4

Epoch: [75]  [51/52]  eta: 0:00:02  lr: 0.000021  loss: 0.0669 (0.0726)  loss_classifier: 0.0096 (0.0119)  loss_box_reg: 0.0158 (0.0203)  loss_mask: 0.0383 (0.0371)  loss_objectness: 0.0003 (0.0011)  loss_rpn_box_reg: 0.0017 (0.0023)  time: 2.5007  data: 0.2015  max mem: 11985
Epoch: [75] Total time: 0:02:03 (2.3691 s / it)                                                                                                                                        model saved for loss_mask=0.03707107973213379


# 5
Epoch    21: reducing learning rate of group 0 to 3.7500e-04. 0.08845961667024173

model saved for loss_mask=0.03692435562753907
Epoch: [107]  [ 0/52]  eta: 0:00:59  lr: 0.000004  loss: 0.0616


