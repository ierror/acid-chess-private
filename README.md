
##

# 1
0.03697541178691955

# 2
Epoch: [89]  [48/49]  eta: 0:00:02  lr: 0.000007  loss: 0.0679 (0.0700)  loss_classifier: 0.0111 (0.0118)  loss_box_reg: 0.0194 (0.0193)  loss_mask: 0.0347 (0.0358)  loss_objectness:
0.0002 (0.0007)  loss_rpn_box_reg: 0.0024 (0.0024)  time: 2.3986  data: 0.1742  max mem: 11006
Epoch: [89] Total time: 0:01:58 (2.4278 s / it)
model saved for loss_mask=0.035843346610057114

#3
Epoch    19: reducing learning rate of group 0 to 3.7500e-04

# 4

Epoch: [75]  [51/52]  eta: 0:00:02  lr: 0.000021  loss: 0.0669 (0.0726)  loss_classifier: 0.0096 (0.0119)  loss_box_reg: 0.0158 (0.0203)  loss_mask: 0.0383 (0.0371)  loss_objectness: 0.0003 (0.0011)  loss_rpn_box_reg: 0.0017 (0.0023)  time: 2.5007  data: 0.2015  max mem: 11985
Epoch: [75] Total time: 0:02:03 (2.3691 s / it)                                                                                                                                        model saved for loss_mask=0.03707107973213379


# 5
Epoch    21: reducing learning rate of group 0 to 3.7500e-04. 0.08845961667024173

model saved for loss_mask=0.03692435562753907
Epoch: [107]  [ 0/52]  eta: 0:00:59  lr: 0.000004  loss: 0.0616


# 6 (transform)
loss_mask=0.03603772188357094

Epoch: [82]  [ 0/57]  eta: 0:01:09  lr: 0.000009  loss: 0.0818 (0.0818)  loss_classifier: 0.0187 (0.0187)  loss_box_reg: 0.0323 (0.0323)  loss_mask: 0.0278 (0.0278)  loss_objectness: 0.0004 (0.0004)  loss_rpn_box_reg: 0.0027 (0.0027)  time: 1.2109  data: 0.1957  max mem: 11317

# 6 (optical distortion)

